{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('pre_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       int64\n",
       "reviewText      object\n",
       "review_clean    object\n",
       "sentiment       object\n",
       "tokenized       object\n",
       "token_count      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['token_count'] < 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72643, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['reviewText', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviewText'] = data['reviewText'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviewText'] = data['reviewText'].apply(lambda x: x.lower()) #lower caseing\n",
    "data['reviewText'] = data['reviewText'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x))) # removing special chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it diffuses a very mild light perfume just wha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all time favorite wish they still carried this</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one of my wifes favorites</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you have body acne this product is a must i...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i really is what i expected</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText sentiment\n",
       "0  it diffuses a very mild light perfume just wha...  Positive\n",
       "1     all time favorite wish they still carried this  Positive\n",
       "2                          one of my wifes favorites  Positive\n",
       "3  if you have body acne this product is a must i...  Positive\n",
       "4                        i really is what i expected  Positive"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 2000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data['reviewText'].values)\n",
    "X = tokenizer.texts_to_sequences(data['reviewText'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58114, 488) (58114, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 488, 128)          320000    \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 488, 128)         0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 196)               254800    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 394       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 575,194\n",
      "Trainable params: 575,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(2500, embed_dim, input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "455/455 [==============================] - 36s 70ms/step - loss: 0.3134 - accuracy: 0.8702\n",
      "Epoch 2/15\n",
      "455/455 [==============================] - 32s 71ms/step - loss: 0.2491 - accuracy: 0.8980\n",
      "Epoch 3/15\n",
      "455/455 [==============================] - 32s 71ms/step - loss: 0.2278 - accuracy: 0.9079\n",
      "Epoch 4/15\n",
      "455/455 [==============================] - 33s 72ms/step - loss: 0.2169 - accuracy: 0.9127\n",
      "Epoch 5/15\n",
      "455/455 [==============================] - 33s 72ms/step - loss: 0.2015 - accuracy: 0.9197\n",
      "Epoch 6/15\n",
      "455/455 [==============================] - 33s 73ms/step - loss: 0.1911 - accuracy: 0.9256\n",
      "Epoch 7/15\n",
      "455/455 [==============================] - 33s 73ms/step - loss: 0.1823 - accuracy: 0.9292\n",
      "Epoch 8/15\n",
      "455/455 [==============================] - 33s 73ms/step - loss: 0.1753 - accuracy: 0.9326\n",
      "Epoch 9/15\n",
      "455/455 [==============================] - 33s 73ms/step - loss: 0.1685 - accuracy: 0.9352\n",
      "Epoch 10/15\n",
      "455/455 [==============================] - 33s 73ms/step - loss: 0.1647 - accuracy: 0.9377\n",
      "Epoch 11/15\n",
      "101/455 [=====>........................] - ETA: 25s - loss: 0.1443 - accuracy: 0.9455"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\college\\capstone\\sentiment_3.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/college/capstone/sentiment_3.ipynb#ch0000023?line=0'>1</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/college/capstone/sentiment_3.ipynb#ch0000023?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train, epochs \u001b[39m=\u001b[39;49m \u001b[39m15\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49mbatch_size, verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\capstone3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\capstone3\\lib\\site-packages\\keras\\engine\\training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/engine/training.py?line=1386'>1387</a>\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/engine/training.py?line=1387'>1388</a>\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/engine/training.py?line=1388'>1389</a>\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/engine/training.py?line=1389'>1390</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/engine/training.py?line=1390'>1391</a>\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\capstone3\\lib\\site-packages\\keras\\callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=430'>431</a>\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=431'>432</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=432'>433</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=433'>434</a>\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=434'>435</a>\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=435'>436</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=436'>437</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=437'>438</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\capstone3\\lib\\site-packages\\keras\\callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=294'>295</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=295'>296</a>\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=296'>297</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=297'>298</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=298'>299</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=299'>300</a>\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\capstone3\\lib\\site-packages\\keras\\callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=314'>315</a>\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=315'>316</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=317'>318</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=319'>320</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=320'>321</a>\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\capstone3\\lib\\site-packages\\keras\\callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=353'>354</a>\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=354'>355</a>\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=355'>356</a>\u001b[0m   hook(batch, logs)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=357'>358</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=358'>359</a>\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\capstone3\\lib\\site-packages\\keras\\callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=1032'>1033</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=1033'>1034</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\capstone3\\lib\\site-packages\\keras\\callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=1101'>1102</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=1103'>1104</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=1104'>1105</a>\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=1105'>1106</a>\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/callbacks.py?line=1106'>1107</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\capstone3\\lib\\site-packages\\keras\\utils\\tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/utils/tf_utils.py?line=559'>560</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/utils/tf_utils.py?line=560'>561</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/utils/tf_utils.py?line=562'>563</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\capstone3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/util/nest.py?line=909'>910</a>\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/util/nest.py?line=910'>911</a>\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/util/nest.py?line=912'>913</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/util/nest.py?line=913'>914</a>\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/util/nest.py?line=914'>915</a>\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\capstone3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/util/nest.py?line=909'>910</a>\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/util/nest.py?line=910'>911</a>\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/util/nest.py?line=912'>913</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/util/nest.py?line=913'>914</a>\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/util/nest.py?line=914'>915</a>\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\capstone3\\lib\\site-packages\\keras\\utils\\tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/utils/tf_utils.py?line=553'>554</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/utils/tf_utils.py?line=554'>555</a>\u001b[0m   \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/utils/tf_utils.py?line=555'>556</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/utils/tf_utils.py?line=556'>557</a>\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/utils/tf_utils.py?line=557'>558</a>\u001b[0m   \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/keras/utils/tf_utils.py?line=558'>559</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\capstone3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/framework/ops.py?line=1199'>1200</a>\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/framework/ops.py?line=1200'>1201</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/framework/ops.py?line=1201'>1202</a>\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/framework/ops.py?line=1219'>1220</a>\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/framework/ops.py?line=1220'>1221</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/framework/ops.py?line=1221'>1222</a>\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/framework/ops.py?line=1222'>1223</a>\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/framework/ops.py?line=1223'>1224</a>\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\capstone3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/framework/ops.py?line=1186'>1187</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/framework/ops.py?line=1187'>1188</a>\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/framework/ops.py?line=1188'>1189</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/framework/ops.py?line=1189'>1190</a>\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/Admin/anaconda3/envs/capstone3/lib/site-packages/tensorflow/python/framework/ops.py?line=1190'>1191</a>\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "model.fit(X_train, Y_train, epochs = 15, batch_size=batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix [[ 1341   861]\n",
      " [  460 11867]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.61      0.67      2202\n",
      "           1       0.93      0.96      0.95     12327\n",
      "\n",
      "    accuracy                           0.91     14529\n",
      "   macro avg       0.84      0.79      0.81     14529\n",
      "weighted avg       0.90      0.91      0.91     14529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test,batch_size = batch_size) \n",
    "Y_pred=np.argmax(Y_pred,axis=1)\n",
    "df_test = pd.DataFrame({'true': Y_test.tolist(), 'pred':Y_pred})\n",
    "df_test['true'] = df_test['true'].apply(lambda x: np.argmax(x))\n",
    "print(\"confusion matrix\",confusion_matrix(df_test.true, df_test.pred))\n",
    "print(classification_report(df_test.true, df_test.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "data_majority = data[data['sentiment'] == 'Positive']\n",
    "data_minority = data[data['sentiment'] == 'Negative']\n",
    "\n",
    "bias = data_minority.shape[0]/data_majority.shape[0]\n",
    "# lets split train/test data first then \n",
    "train = pd.concat([data_majority.sample(frac=0.8,random_state=200),\n",
    "         data_minority.sample(frac=0.8,random_state=200)])\n",
    "test = pd.concat([data_majority.drop(data_majority.sample(frac=0.8,random_state=200).index),\n",
    "        data_minority.drop(data_minority.sample(frac=0.8,random_state=200).index)])\n",
    "\n",
    "train = shuffle(train)\n",
    "test = shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive data in training: 49435\n",
      "negative data in training: 8679\n",
      "positive data in test: 12359\n",
      "negative data in test: 2170\n"
     ]
    }
   ],
   "source": [
    "print('positive data in training:',(train.sentiment == 'Positive').sum())\n",
    "print('negative data in training:',(train.sentiment == 'Negative').sum())\n",
    "print('positive data in test:',(test.sentiment == 'Positive').sum())\n",
    "print('negative data in test:',(test.sentiment == 'Negative').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class before upsample: (49435, 2)\n",
      "minority class before upsample: (8679, 2)\n",
      "After upsampling\n",
      "Positive    49435\n",
      "Negative    49435\n",
      "Name: sentiment, dtype: int64\n",
      "x_train shape: (98870, 488)\n",
      "x_test shape (14529, 488)\n"
     ]
    }
   ],
   "source": [
    "# Separate majority and minority classes in training data for upsampling \n",
    "data_majority = train[train['sentiment'] == 'Positive']\n",
    "data_minority = train[train['sentiment'] == 'Negative']\n",
    "\n",
    "print(\"majority class before upsample:\",data_majority.shape)\n",
    "print(\"minority class before upsample:\",data_minority.shape)\n",
    "\n",
    "# Upsample minority class\n",
    "data_minority_upsampled = resample(data_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples= data_majority.shape[0],    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data_upsampled = pd.concat([data_majority, data_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print(\"After upsampling\\n\",data_upsampled.sentiment.value_counts(),sep = \"\")\n",
    "\n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['reviewText'].values) # training with whole data\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(data_upsampled['reviewText'].values)\n",
    "X_train = pad_sequences(X_train,maxlen=488)\n",
    "Y_train = pd.get_dummies(data_upsampled['sentiment']).values\n",
    "print('x_train shape:',X_train.shape)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(test['reviewText'].values)\n",
    "X_test = pad_sequences(X_test,maxlen=488)\n",
    "Y_test = pd.get_dummies(test['sentiment']).values\n",
    "print(\"x_test shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (98870, 488)\n",
      "x_test shape (14529, 488)\n"
     ]
    }
   ],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['reviewText'].values) # training with whole data\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(data_upsampled['reviewText'].values)\n",
    "X_train = pad_sequences(X_train,maxlen=488)\n",
    "Y_train = pd.get_dummies(data_upsampled['sentiment']).values\n",
    "print('x_train shape:',X_train.shape)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(test['reviewText'].values)\n",
    "X_test = pad_sequences(X_test,maxlen=488)\n",
    "Y_test = pd.get_dummies(test['sentiment']).values\n",
    "print(\"x_test shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 488, 128)          320000    \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spatia  (None, 488, 128)         0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 196)               254800    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 394       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 575,194\n",
      "Trainable params: 575,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(2500, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\capstone3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773/773 [==============================] - 64s 82ms/step - loss: 1.0856 - accuracy: 0.6682\n",
      "Epoch 2/10\n",
      "773/773 [==============================] - 64s 83ms/step - loss: 0.8527 - accuracy: 0.7497\n",
      "Epoch 3/10\n",
      "773/773 [==============================] - 64s 83ms/step - loss: 0.7681 - accuracy: 0.7819\n",
      "Epoch 4/10\n",
      "773/773 [==============================] - 64s 83ms/step - loss: 0.7146 - accuracy: 0.7979\n",
      "Epoch 5/10\n",
      "773/773 [==============================] - 65s 84ms/step - loss: 0.6521 - accuracy: 0.8205\n",
      "Epoch 6/10\n",
      "773/773 [==============================] - 65s 84ms/step - loss: 0.6134 - accuracy: 0.8309\n",
      "Epoch 7/10\n",
      "773/773 [==============================] - 65s 84ms/step - loss: 0.5717 - accuracy: 0.8463\n",
      "Epoch 8/10\n",
      "773/773 [==============================] - 65s 84ms/step - loss: 0.5329 - accuracy: 0.8589\n",
      "Epoch 9/10\n",
      "773/773 [==============================] - 65s 84ms/step - loss: 0.4887 - accuracy: 0.8707\n",
      "Epoch 10/10\n",
      "773/773 [==============================] - 65s 84ms/step - loss: 0.4580 - accuracy: 0.8802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19dd62f45b0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "# also adding weights\n",
    "class_weights = {0: 1 ,\n",
    "                1: 1.6/bias }\n",
    "model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, verbose = 1,\n",
    "          class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix [[ 1131  1039]\n",
      " [  363 11996]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.52      0.62      2170\n",
      "           1       0.92      0.97      0.94     12359\n",
      "\n",
      "    accuracy                           0.90     14529\n",
      "   macro avg       0.84      0.75      0.78     14529\n",
      "weighted avg       0.90      0.90      0.90     14529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test,batch_size = batch_size) \n",
    "Y_pred=np.argmax(Y_pred,axis=1)\n",
    "df_test = pd.DataFrame({'true': Y_test.tolist(), 'pred':Y_pred})\n",
    "df_test['true'] = df_test['true'].apply(lambda x: np.argmax(x))\n",
    "print(\"confusion matrix\",confusion_matrix(df_test.true, df_test.pred))\n",
    "print(classification_report(df_test.true, df_test.pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - 33ms/epoch - 33ms/step\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "twt = ['Bad smell is coming from air conditioner']\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "twt = tokenizer.texts_to_sequences(twt)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "twt = pad_sequences(twt, maxlen=488, dtype='int32', value=0)\n",
    "\n",
    "sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n",
    "if(np.argmax(sentiment) == 0):\n",
    "    print(\"negative\")\n",
    "elif (np.argmax(sentiment) == 1):\n",
    "    print(\"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.35\n",
      "acc: 0.90\n"
     ]
    }
   ],
   "source": [
    "validation_size = 1500\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]\n",
    "score,acc = model.evaluate(X_test, Y_test, verbose = 0, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model12.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afcb804707279b9b642cf2a94c26a02d7fe35902e873945e34f9c8bae120ddc3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('capstone3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
